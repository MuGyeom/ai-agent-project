# 7. Pessimistic Lock for Duplicate Processing Prevention

* Status: Accepted
* Date: 2026-01-09
* Context: Phase 2.5 (Concurrency Control)

## Context and Problem Statement

ë¶„ì‚° Worker í™˜ê²½ì—ì„œ Kafka ë©”ì‹œì§€ ì²˜ë¦¬ ì‹œ ë‹¤ìŒê³¼ ê°™ì€ ë™ì‹œì„± ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:

1. **ì¤‘ë³µ ì²˜ë¦¬**: ê°™ì€ request_idê°€ ì—¬ëŸ¬ ë²ˆ ì²˜ë¦¬ë¨
2. **ë°ì´í„° ë¶ˆì¼ì¹˜**: ë™ì¼ ìš”ì²­ì— ëŒ€í•´ ì—¬ëŸ¬ ê°œì˜ ê²€ìƒ‰ ê²°ê³¼/ë¶„ì„ ê²°ê³¼ ì €ì¥
3. **Race Condition**: ì—¬ëŸ¬ Workerê°€ ë™ì‹œì— ê°™ì€ ìš”ì²­ ì²˜ë¦¬ ì‹œë„
4. **Consumer Rebalancing**: Kafka rebalance ì‹œ ë©”ì‹œì§€ ì¬ì „ë‹¬

**ë¬¸ì œ ì‹œë‚˜ë¦¬ì˜¤**:
```
[Kafka] â†’ topic: search-queue, request_id: abc-123

[Search Worker 1] receives message â†’ starts processing
[Search Worker 2] receives message (rebalance) â†’ starts processing

Result: Duplicate search results for abc-123!
```

**í•„ìš”ì‚¬í•­**:
- ê° ìš”ì²­ì€ ì •í™•íˆ í•œ ë²ˆë§Œ ì²˜ë¦¬ (Exactly-Once Semantics)
- Worker ê°„ ê²½ìŸ ìƒíƒœ ë°©ì§€
- ì²˜ë¦¬ ì¤‘ì¸ ìš”ì²­ì€ ë‹¤ë¥¸ Workerê°€ ê±´ë“œë¦¬ì§€ ëª»í•¨

## Decision Drivers

* **ë°ì´í„° ì •í•©ì„±**: ì¤‘ë³µ ë°ì´í„° ì €ì¥ ë°©ì§€
* **ì„±ëŠ¥**: ë½ ì˜¤ë²„í—¤ë“œ ìµœì†Œí™”
* **í™•ì¥ì„±**: Worker ìˆ˜ ì¦ê°€ì—ë„ ì•ˆì •ì 
* **ë³µì¡ë„**: ë¶„ì‚° ë½ ì„œë¹„ìŠ¤ ë„ì… ì§€ì–‘
* **ê¸°ì¡´ ì¸í”„ë¼ í™œìš©**: PostgreSQL ì´ë¯¸ ì‚¬ìš© ì¤‘

## Considered Options

### Option 1: PostgreSQL Row-Level Locking (SELECT FOR UPDATE SKIP LOCKED)
**Pros**:
- âœ… ì¶”ê°€ ì¸í”„ë¼ ë¶ˆí•„ìš” (PostgreSQL ë‚´ì¥)
- âœ… ACID ë³´ì¥
- âœ… SKIP LOCKEDë¡œ ëŒ€ê¸° ì—†ì´ ìŠ¤í‚µ
- âœ… ìë™ ë½ í•´ì œ (íŠ¸ëœì­ì…˜ ì¢…ë£Œ ì‹œ)
- âœ… Deadlock ë°©ì§€ (SKIP LOCKED)

**Cons**:
- âŒ DB ë¶€í•˜ ì¦ê°€ (ë¯¸ë¯¸í•¨)
- âŒ íŠ¸ëœì­ì…˜ ë²”ìœ„ ë‚´ì—ì„œë§Œ ìœ íš¨

### Option 2: Redis Distributed Lock (Redlock)
**Pros**:
- âœ… ê³ ì„±ëŠ¥ ë½
- âœ… ë¶„ì‚° í™˜ê²½ í‘œì¤€
- âœ… TTL ê¸°ë°˜ ìë™ í•´ì œ

**Cons**:
- âŒ Redis ì¸í”„ë¼ ì¶”ê°€ í•„ìš”
- âŒ Redlock êµ¬í˜„ ë³µì¡
- âŒ ë„¤íŠ¸ì›Œí¬ íŒŒí‹°ì…˜ ì‹œ ë¬¸ì œ

### Option 3: Kafka Consumer Partition Assignment
**Pros**:
- âœ… Kafka ìì²´ ê¸°ëŠ¥ í™œìš©
- âœ… íŒŒí‹°ì…˜ ë‹¨ìœ„ ì²˜ë¦¬ ë³´ì¥

**Cons**:
- âŒ íŒŒí‹°ì…˜ ìˆ˜ì— ì˜ì¡´
- âŒ Rebalance ì‹œ ì¤‘ë³µ ê°€ëŠ¥
- âŒ ì™„ì „í•œ Exactly-Once ì•„ë‹˜

### Option 4: Application-Level Deduplication (Set/Cache)
**Pros**:
- âœ… ê°„ë‹¨í•œ êµ¬í˜„

**Cons**:
- âŒ ë©”ëª¨ë¦¬ ë‚´ì—ì„œë§Œ ìœ íš¨
- âŒ Worker ì¬ì‹œì‘ ì‹œ ìƒíƒœ ì†ì‹¤
- âŒ ë¶„ì‚° í™˜ê²½ ë¯¸ì§€ì›

## Decision Outcome

**PostgreSQL SELECT FOR UPDATE SKIP LOCKED**ë¥¼ ì„ íƒí–ˆìŠµë‹ˆë‹¤.

### Rationale

1. **Zero Infrastructure**:
   - PostgreSQL ì´ë¯¸ ì‚¬ìš© ì¤‘
   - Redis ì¶”ê°€ ë¶ˆí•„ìš”

2. **SKIP LOCKED ì¥ì **:
   ```sql
   SELECT id, status 
   FROM requests 
   WHERE id = :request_id 
   AND status = 'searching'
   FOR UPDATE SKIP LOCKED
   ```
   - ë½ íšë“ ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ ìŠ¤í‚µ (ë¸”ë¡œí‚¹ ì—†ìŒ)
   - Deadlock ë¶ˆê°€ëŠ¥

3. **ìƒíƒœ ê¸°ë°˜ ì´ì¤‘ ë³´í˜¸**:
   ```
   ë½ ì¡°ê±´: status = 'searching' (ë˜ëŠ” 'analyzing')
   â””â”€ ë½ íšë“ ì„±ê³µ â†’ ì¦‰ì‹œ status = 'processing_search' ë³€ê²½
   â””â”€ ë‹¤ë¥¸ Workerê°€ ê°™ì€ ìš”ì²­ ì¡°íšŒ â†’ ìƒíƒœê°€ ë‹¬ë¼ì„œ ë§¤ì¹˜ ì•ˆë¨
   ```

4. **íŠ¸ëœì­ì…˜ ë³´ì¥**:
   - ë½ íšë“ + ìƒíƒœ ë³€ê²½ + ì»¤ë°‹ì´ ì›ìì 
   - ì‹¤íŒ¨ ì‹œ ìë™ ë¡¤ë°±

---

## Implementation Details

### 1. Search Worker

```python
# src/search-worker/main.py

for message in consumer.get_messages():
    db = SessionLocal()
    try:
        task = message.value
        request_id = task.get("request_id")
        topic = task.get("topic")

        # ğŸ”’ Pessimistic Lock: Row-level locking
        from sqlalchemy import text
        
        lock_query = text("""
            SELECT id, status 
            FROM requests 
            WHERE id = :request_id 
            AND status = 'searching'
            FOR UPDATE SKIP LOCKED
        """)
        
        result = db.execute(lock_query, {"request_id": request_id}).fetchone()
        
        if not result:
            # Case 1: ì´ë¯¸ ë‹¤ë¥¸ Workerê°€ ë½ ë³´ìœ 
            # Case 2: ìƒíƒœê°€ ì´ë¯¸ ë³€ê²½ë¨ (processing_search, completed ë“±)
            existing = db.query(Request).filter(Request.id == request_id).first()
            if existing:
                if existing.status == 'searching':
                    print(f"ğŸ”’ Request {request_id} locked by another worker, skipping")
                else:
                    print(f"â­ï¸  Request {request_id} already processed (status: {existing.status})")
            consumer.consumer.commit()
            continue

        # âœ… ë½ íšë“ ì„±ê³µ! ì¦‰ì‹œ ìƒíƒœ ë³€ê²½ (ë‹¤ë¥¸ Worker ì°¨ë‹¨)
        db_request = db.query(Request).filter(Request.id == request_id).first()
        db_request.status = 'processing_search'
        db.commit()
        print(f"âœ… Locked and claimed request {request_id}")

        # ê²€ìƒ‰ ë¡œì§ ìˆ˜í–‰...
        search_results_data = search_and_crawl(topic, max_results=8)
        
        # DB ì €ì¥ ë° ìƒíƒœ ì—…ë°ì´íŠ¸
        db_request.status = "analyzing"
        db.commit()

    except Exception as e:
        # ì—ëŸ¬ ìƒíƒœ ì €ì¥
        db_request.status = "failed"
        db_request.error_message = str(e)
        db.commit()
    finally:
        db.close()
```

### 2. AI Worker

```python
# src/ai-worker/main.py

for message in consumer.get_messages():
    db = SessionLocal()
    try:
        task = message.value
        request_id = task.get("request_id")

        # ğŸ”’ Pessimistic Lock
        lock_query = text("""
            SELECT id, status 
            FROM requests 
            WHERE id = :request_id 
            AND status = 'analyzing'
            FOR UPDATE SKIP LOCKED
        """)
        
        result = db.execute(lock_query, {"request_id": request_id}).fetchone()
        
        if not result:
            # ë½ íšë“ ì‹¤íŒ¨ ë˜ëŠ” ì´ë¯¸ ì²˜ë¦¬ë¨
            existing = db.query(Request).filter(Request.id == request_id).first()
            if existing:
                if existing.status == 'analyzing':
                    print(f"ğŸ”’ Request {request_id} locked by another worker, skipping")
                else:
                    print(f"â­ï¸  Request {request_id} already processed (status: {existing.status})")
            consumer.consumer.commit()
            continue

        # âœ… ë½ íšë“ ì„±ê³µ!
        db_request = db.query(Request).filter(Request.id == request_id).first()
        db_request.status = 'processing_analysis'
        db.commit()
        print(f"âœ… Locked and claimed request {request_id}")

        # AI ë¶„ì„ ìˆ˜í–‰...
        summary, inference_time_ms = analyze_search_results(request_id, topic, db, llm)
        
        # ì™„ë£Œ ì²˜ë¦¬
        db_request.status = "completed"
        db_request.completed_at = datetime.utcnow()
        db.commit()

    except Exception as e:
        db_request.status = "failed"
        db_request.error_message = str(e)
        db.commit()
    finally:
        db.close()
```

---

### 3. Status State Machine

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        REQUEST LIFECYCLE                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  pending â”€â”€â†’ searching â”€â”€â†’ processing_search â”€â”€â†’ analyzing     â”‚
â”‚      â”‚           â”‚               â”‚                    â”‚         â”‚
â”‚      â”‚           â”‚               â”‚                    â–¼         â”‚
â”‚      â”‚           â”‚               â”‚          processing_analysis â”‚
â”‚      â”‚           â”‚               â”‚                    â”‚         â”‚
â”‚      â”‚           â”‚               â”‚                    â–¼         â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ completed    â”‚
â”‚                         â”‚                              â”‚         â”‚
â”‚                         â–¼                              â”‚         â”‚
â”‚                      failed â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ìƒíƒœ ì„¤ëª…:
- pending: APIì—ì„œ ìƒì„±ë¨
- searching: Kafka ë°œí–‰ í›„ (Search Worker ëŒ€ê¸° ì¤‘)
- processing_search: Search Workerê°€ ë½ íšë“ (ì²˜ë¦¬ ì¤‘)
- analyzing: ê²€ìƒ‰ ì™„ë£Œ, AI Worker ëŒ€ê¸° ì¤‘
- processing_analysis: AI Workerê°€ ë½ íšë“ (ì²˜ë¦¬ ì¤‘)
- completed: ëª¨ë“  ì²˜ë¦¬ ì™„ë£Œ
- failed: ì–´ëŠ ë‹¨ê³„ì—ì„œë“  ì—ëŸ¬ ë°œìƒ
```

---

### 4. Kafka Consumer Configuration

```python
# Manual commit for at-least-once delivery
consumer = KafkaConsumer(
    topic,
    bootstrap_servers=settings.KAFKA_BOOTSTRAP_SERVERS,
    group_id=group_id,
    auto_offset_reset="earliest",
    enable_auto_commit=False,  # âš ï¸ ì¤‘ìš”: ìˆ˜ë™ ì»¤ë°‹
    value_deserializer=lambda m: json.loads(m.decode("utf-8"))
)

# ì²˜ë¦¬ ì™„ë£Œ í›„ ëª…ì‹œì  ì»¤ë°‹
for message in consumer:
    try:
        process_message(message)
        consumer.commit()  # âœ… ì„±ê³µ ì‹œì—ë§Œ ì»¤ë°‹
    except Exception as e:
        # ì—ëŸ¬ ì‹œ ì»¤ë°‹í•˜ì§€ ì•ŠìŒ â†’ ì¬ì‹œë„ ê°€ëŠ¥
        log_error(e)
```

---

## Consequences

### Positive

1. âœ… **ì¤‘ë³µ ì²˜ë¦¬ ì™„ë²½ ë°©ì§€**: ê° ìš”ì²­ì€ ì •í™•íˆ í•œ ë²ˆë§Œ ì²˜ë¦¬
2. âœ… **ë°ì´í„° ì •í•©ì„±**: ì¤‘ë³µ ê²€ìƒ‰ ê²°ê³¼/ë¶„ì„ ê²°ê³¼ ì—†ìŒ
3. âœ… **ì¶”ê°€ ì¸í”„ë¼ ë¶ˆí•„ìš”**: PostgreSQL ë‚´ì¥ ê¸°ëŠ¥ í™œìš©
4. âœ… **Deadlock ì—†ìŒ**: SKIP LOCKED ì‚¬ìš©
5. âœ… **ìƒíƒœ ì¶”ì  ìš©ì´**: processing_* ìƒíƒœë¡œ í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ìš”ì²­ ì‹ë³„
6. âœ… **ìë™ ë³µêµ¬**: Worker í¬ë˜ì‹œ ì‹œ íŠ¸ëœì­ì…˜ ë¡¤ë°±

### Negative

1. âŒ **DB ë¼ìš´ë“œíŠ¸ë¦½ ì¶”ê°€**:
   - ë©”ì‹œì§€ë‹¹ 1íšŒ ì¶”ê°€ ì¿¼ë¦¬ (SELECT FOR UPDATE)
   - ì„±ëŠ¥ ì˜í–¥ ë¯¸ë¯¸ (ë¡œì»¬ DB ê¸°ì¤€ <1ms)

2. âŒ **ìƒíƒœ ë³µì¡ë„ ì¦ê°€**:
   - ê¸°ì¡´ 5ê°œ â†’ 7ê°œ ìƒíƒœ
   - processing_search, processing_analysis ì¶”ê°€

3. âŒ **ì‹¤íŒ¨ ë³µêµ¬ í•„ìš”**:
   - processing_* ìƒíƒœë¡œ ë©ˆì¶˜ ìš”ì²­ ìˆ˜ë™ ì²˜ë¦¬ í•„ìš”
   - í–¥í›„ ìë™ íƒ€ì„ì•„ì›ƒ ë¡œì§ ì¶”ê°€ ê³ ë ¤

---

## Performance Impact

### Before (Without Lock)
- ë©”ì‹œì§€ ìˆ˜ì‹  â†’ ì¦‰ì‹œ ì²˜ë¦¬ ì‹œì‘
- ë¬¸ì œ: ì¤‘ë³µ ì²˜ë¦¬ ë°œìƒ

### After (With Lock)
- ë©”ì‹œì§€ ìˆ˜ì‹  â†’ ë½ ì¿¼ë¦¬ â†’ ì²˜ë¦¬ ì‹œì‘
- ì¶”ê°€ ì§€ì—°: ~1ms (PostgreSQL ì¿¼ë¦¬)

**ì‹¤ì¸¡**:
- ë½ ì¿¼ë¦¬: 0.5-2ms
- ì „ì²´ ì²˜ë¦¬ ì‹œê°„ ëŒ€ë¹„: <0.1% ì¦ê°€

---

## Dashboard Integration

ìƒíƒœë³„ ìƒ‰ìƒ í‘œì‹œ ì¶”ê°€:

```javascript
const STATUS_COLORS = {
    pending: 'bg-yellow-100 text-yellow-800',
    searching: 'bg-blue-100 text-blue-800',
    processing_search: 'bg-blue-200 text-blue-900',    // ìƒˆë¡œ ì¶”ê°€
    analyzing: 'bg-purple-100 text-purple-800',
    processing_analysis: 'bg-purple-200 text-purple-900', // ìƒˆë¡œ ì¶”ê°€
    completed: 'bg-green-100 text-green-800',
    failed: 'bg-red-100 text-red-800',
};
```

---

## Alternative: Unique Constraint

ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•œ ë˜ ë‹¤ë¥¸ ë°©ë²•:

```sql
-- ê²€ìƒ‰ ê²°ê³¼ í…Œì´ë¸”ì— ìœ ë‹ˆí¬ ì œì•½ ì¶”ê°€
ALTER TABLE search_results 
ADD CONSTRAINT unique_request_url 
UNIQUE (request_id, url);
```

**ì±„íƒí•˜ì§€ ì•Šì€ ì´ìœ **:
- INSERT ì‹œ ì—ëŸ¬ ë°œìƒ â†’ ì²˜ë¦¬ ë¡œì§ ë³µì¡í•´ì§
- ë½ì´ ë” ê¹”ë”í•œ í•´ê²°ì±…

---

## Future Enhancements

### 1. Stale Processing Detection
```python
# ì²˜ë¦¬ ì¤‘ ìƒíƒœë¡œ ì˜¤ë˜ ë¨¸ë¬¸ ìš”ì²­ ìë™ ì‹¤íŒ¨ ì²˜ë¦¬
UPDATE requests 
SET status = 'failed', error_message = 'Timeout'
WHERE status IN ('processing_search', 'processing_analysis')
AND updated_at < NOW() - INTERVAL '10 minutes';
```

### 2. Retry Queue
```python
# ì‹¤íŒ¨í•œ ìš”ì²­ ì¬ì‹œë„ í
if should_retry(db_request):
    producer.send_data(
        topic="retry-queue",
        value={"request_id": request_id, "retry_count": count + 1}
    )
```

### 3. Redis Cache for Lock Status
```python
# ë½ ìƒíƒœ ìºì‹± (DB ë¶€í•˜ ê°ì†Œ)
if redis.get(f"lock:{request_id}"):
    skip()  # ì´ë¯¸ ì²˜ë¦¬ ì¤‘
```

---

## References

- [PostgreSQL SELECT FOR UPDATE](https://www.postgresql.org/docs/current/sql-select.html#SQL-FOR-UPDATE-SHARE)
- [SKIP LOCKED](https://www.2ndquadrant.com/en/blog/what-is-select-skip-locked-for-in-postgresql-9-5/)
- [Kafka Consumer Groups](https://docs.confluent.io/platform/current/clients/consumer.html)
