import time
import trafilatura
from duckduckgo_search import DDGS
from common.config import settings
from common.utils import KafkaConsumerWrapper, KafkaProducerWrapper
from common.database import SessionLocal, Request, SearchResult


def search_and_crawl(topic, max_results=5):
    """
    1. DuckDuckGo ê²€ìƒ‰
    2. ìƒìœ„ Nê°œ URL ìˆ˜ì§‘
    3. ë³¸ë¬¸ í¬ë¡¤ë§
    4. ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜ (DB ì €ì¥ìš©)
    """
    print(f"ğŸ” Searching for: {topic}")
    results = []

    # 1. ê²€ìƒ‰ ìˆ˜í–‰
    try:
        with DDGS() as ddgs:
            search_results = list(ddgs.text(topic, max_results=max_results))

        for result in search_results:
            url = result["href"]
            title = result["title"]
            print(f"   ğŸ‘‰ Found: {title} ({url})")

            # 2. ë³¸ë¬¸ í¬ë¡¤ë§ (trafilatura)
            downloaded = trafilatura.fetch_url(url)
            content = ""
            if downloaded:
                text = trafilatura.extract(downloaded)
                if text:
                    content = text[:2000]  # 2000ì ì œí•œ
                else:
                    print(f"      âš ï¸ No content extracted from {url}")
            else:
                print(f"      âš ï¸ Failed to fetch {url}")

            # ê²°ê³¼ ì €ì¥ (DB ì €ì¥ìš©)
            results.append({
                "url": url,
                "title": title,
                "content": content
            })

            time.sleep(1)  # ì°¨ë‹¨ ë°©ì§€ë¥¼ ìœ„í•œ ì˜ˆì˜ë°”ë¥¸ ëŒ€ê¸°

    except Exception as e:
        print(f"âŒ Search Error: {e}")

    return results


def process_search():
    consumer = KafkaConsumerWrapper(
        topic=settings.KAFKA_TOPIC_SEARCH, group_id=settings.KAFKA_GROUP_SEARCH
    )
    producer = KafkaProducerWrapper()

    print(f"ğŸš€ [Search Worker] Ready using DuckDuckGo...")

    for message in consumer.get_messages():
        db = SessionLocal()
        try:
            task = message.value
            request_id = task.get("request_id")
            topic = task.get("topic")

            print(f"ğŸ“¥ Received request {request_id}: {topic}")

            # ê²€ìƒ‰ ë° í¬ë¡¤ë§ ìˆ˜í–‰
            search_results_data = search_and_crawl(topic)

            if not search_results_data:
                print(f"âš ï¸ No search results found for {topic}")
                # ìƒíƒœë¥¼ failedë¡œ ì—…ë°ì´íŠ¸
                db_request = db.query(Request).filter(Request.id == request_id).first()
                if db_request:
                    db_request.status = "failed"
                    db_request.error_message = "No search results found"
                    db.commit()
                continue

            # DBì— ê²€ìƒ‰ ê²°ê³¼ ì €ì¥
            for result_data in search_results_data:
                search_result = SearchResult(
                    request_id=request_id,
                    url=result_data['url'],
                    title=result_data['title'],
                    content=result_data['content']
                )
                db.add(search_result)
            
            db.commit()
            print(f"ğŸ’¾ Saved {len(search_results_data)} search results to DB")

            # ìš”ì²­ ìƒíƒœ ì—…ë°ì´íŠ¸: searching â†’ analyzing
            db_request = db.query(Request).filter(Request.id == request_id).first()
            if db_request:
                db_request.status = "analyzing"
                db.commit()
                print(f"ğŸ”„ Status updated to 'analyzing' for request {request_id}")

            # AI Workerë¡œ ì „ì†¡ (request_idë§Œ ì „ì†¡ - AI Workerê°€ DBì—ì„œ ì½ì„ ê²ƒ)
            producer.send_data(
                topic=settings.KAFKA_TOPIC_AI,
                value={"request_id": request_id, "topic": topic}
            )
            print(f"âœ… [Forwarded] Sent to AI Worker for analysis")

        except Exception as e:
            print(f"âŒ Worker Error: {e}")
            # ì—ëŸ¬ ìƒíƒœ ì €ì¥
            if 'request_id' in locals() and request_id:
                db_request = db.query(Request).filter(Request.id == request_id).first()
                if db_request:
                    db_request.status = "failed"
                    db_request.error_message = str(e)
                    db.commit()
        finally:
            db.close()


if __name__ == "__main__":
    process_search()
