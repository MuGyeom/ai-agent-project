import trafilatura  # í¬ë¡¤ë§ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ì›Œì»¤ì—ì„œë§Œ ì„í¬íŠ¸
from common.utils import KafkaConsumerWrapper, KafkaProducerWrapper
from common.config import settings


def process_search():
    # 1. Consumer: search-queueì—ì„œ í•  ì¼ ê°€ì ¸ì˜´
    consumer = KafkaConsumerWrapper(
        topic=settings.KAFKA_TOPIC_SEARCH, group_id=settings.KAFKA_GROUP_SEARCH
    )

    # 2. Producer: ê²°ê³¼ë¬¼ì„ ai-queueë¡œ ë³´ëƒ„
    producer = KafkaProducerWrapper()

    for message in consumer.get_messages():
        task = message.value
        keyword = task["topic"]
        print(f"ğŸ” Crawling: {keyword}")

        # --- í¬ë¡¤ë§ ë¡œì§ (ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§) ---
        # ì‹¤ì œë¡œëŠ” ì—¬ê¸°ì„œ êµ¬ê¸€ ê²€ìƒ‰ í›„ URLì„ ë”°ì™€ì•¼ í•˜ì§€ë§Œ ì˜ˆì‹œë¡œ ì§ê´€ì ì¸ URL ì‚¬ìš©
        downloaded = trafilatura.fetch_url("https://example.com")
        content = trafilatura.extract(downloaded) if downloaded else ""
        # ------------------------------

        # ë‹¤ìŒ ë‹¨ê³„ë¡œ ì „ì†¡
        producer.send_data(
            topic=settings.KAFKA_TOPIC_SEARCH,
            value={"context": content, "original_topic": keyword},
        )


if __name__ == "__main__":
    process_search()
