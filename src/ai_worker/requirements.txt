# Kafka & Config
kafka-python
pydantic-settings

# LLM Inference
vllm==0.6.3  # Pinned to 0.6.3 (stable v0 API, no v1 bugs)
transformers>=4.40.0,<4.46.0  # Pin transformers for vLLM 0.6.3 compatibility
torch

# Database
sqlalchemy
psycopg2-binary